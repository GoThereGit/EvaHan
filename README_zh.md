# 欢迎参赛 | EvaHan2026 古籍多模态OCR国际评测

<div align='center'>
<img src = 'https://user-images.githubusercontent.com/54113513/201254029-e63dd695-22aa-4419-ac01-7fc34326625a.png'>
</div>


[![En](https://img.shields.io/badge/README-English-blue.svg "English")](./README.md)

**English Version:** <a href="https://github.com/GoThereGit/EvaHan/blob/main/README_zh.md">CLICK ME</a> 

## 最新消息
评测报名入口：<a href="https://jsj.top/f/nWLK2R">点此跳转</a>

## 背景

中国古代典籍是中华文明最重要的载体之一，对其进行大规模数字化、智能化利用，是数字技术繁盛的当代，传承中华文明的重要方式。然而，光学字符识别（OCR）技术因古籍文本的异体字、残损笔迹等特殊难题，一直以来都是制约古籍文本实现大规模数字化、智能化的瓶颈。近年来，多模态大语言模型的迅猛发展，为突破上述技术瓶颈提供了新的可能。因此，如何科学评估其在复杂古籍图像（印刷体、版刻混排、手写体）上的OCR与版面分析能力，已成为当前领域的前沿课题。

为持续推动中文古籍智能处理技术发展，由南京农业大学、南京师范大学、南京理工大学等多单位联合主办的EvaHan 2026国际评测将于2026年正式开展，评测会议将于5月11日-5月16日在西班牙马略卡岛LREC 2026子会议上举办。这是第五届针对古代汉语语言技术的国际测评，本次测评聚焦于利用大语言模型（LLMs）进行古代汉语OCR识别任务，力图评价大语言模型的实际应用能力。

## 01 评测简介

光学字符识别（Optical Character Recognition，OCR）是一种将印刷或手写文本的图片转换为机器编码文本的基础技术。OCR的准确率与速率直接决定着系统整体性能，并影响文档数字化、信息提取及智能检索等下游应用的用户体验。然而，古籍文档的排版和布局与现代印刷存在显著差异，这使得海量基于现代文档数据开发的OCR技术及模型，在处理古籍相关图像时往往难以达到理想的识别效果。加之古籍本身存在文字形态复杂、版式多样等诸多特性，古籍OCR识别至今仍是一项颇具挑战的任务。

中国古代典籍承载着中华数千年的文化与历史信息，是传承民族文化基因的核心载体，其自动化处理有助于突破传统人工整理的效率瓶颈与资源限制，实现古籍文献的规模化、数字化存档，推动传统文化的活化利用与广泛传播，让珍贵典籍中的智慧成果更好服务于当代社会。迄今为止，EvaHan已成功举办了四届，有力推动了古籍智能分析技术的发展。

- 2022年（法国马赛）古汉语分词与词性标注国际评测
- 2023年（中国澳门）古汉语机器翻译国际评测
- 2024年（意大利都灵）古汉语自动句读与标点国际评测
- 2025年（美国阿尔伯克基）古汉语命名实体识别国际评测

EvaHan 2026国际评测组织者将会为参赛者提供统一的训练和测试数据集，参赛者则需要提交在测试集上的实验结果，由组织者评估参赛者最终提交的数据的真实性。

2026年，我们将目光转向更具挑战性的古籍多模态OCR任务，首次系统评估大语言模型在真实古籍图像上的端到端识别与版面理解能力。

## 02 重要时间节点（UTC+8，北京时间）

- 注册开放：2025年12月1日
- 训练数据发布：2026年1月1日
- 注册截止：2026年1月30日
- 测试数据发布：2026年2月3日 23:50 ~~2026年2月1日~~
- 结果提交截止：2026年2月9日 23:50
- 技术报告提交截止：2026年2月28日
- 录用通知：2026年3月1日
- 论文终稿提交：2026年3月10日
- 会议时间：2026年5月11-16日（西班牙·马略卡岛）

## 03 评测方法

EvaHan 2026数据集包括三类图像文本对：版刻图像、混合图文图像及手写文本图像，经过自动标注及专家修订后形成高质量的训练和测试集。数据来源包括：

- 数据集A（印刷文本）选自《四库全书》里的经史子集。 
- 数据集B（混合版式）包含从《四库全书》及其他古籍中选取的混合图文数据。 
- 数据集C（手写文本）涵盖手写古籍，主要为汉文佛典，包含《汉文佛典（TKH）》数据集与《汉文佛典（MTH）》数据集。

数据集被分成训练集（约15000组）与测试集（每个子集约200–500组），所有评估数据均采用“图像-文本”对形式，以json文件存储。

核心评估维度：

- OCR性能：CER(字错率)、准确率（Precision）、召回率（Recall）、F1-Score和NED（归一化编辑距离）
- 版面分析指标：mAP、微平均F1、宏平均F1、IoU

表1. ocr文本识别评测指标
<img src="img/image5.png" alt="OCR Task">

表2. 版面要素识别评测指标
<img src="img/image6.png" alt="Page Recognition">

测试数据的详细信息和下载链接，均将在正式评估期开始前提供给参与者。

## 04 两种参赛模式

每个参赛队伍都可以提交两种模式的成绩。

在**封闭模式**中，每个团队只能使用官方训练数据、两个指定模型（Qwen2.5-VL-7B-Instruct 或 Xunzi_Qwen2_VL_7B_Instruct）或其他传统机器学习模型。请注意，在封闭模式中，参赛团队不能使用其他外部语料库作为训练数据，也不应使用其他大语言模型（考虑到大语言模型通常在庞大数据集上训练，不适合封闭赛道）。

在**开放模式**中，资源、数据或模型没有限制。可以使用带注释的外部数据，如处理后的图像或文本。然而，每个团队必须在最终报告中披露每个系统中使用的所有资源、数据和模型。

## 05 参赛方式

- 注册：2025年12月1日–2026年1月30日，发送邮件至[evahan2026@gmail.com](mailto:evahan2026@gmail.com)索取并提交注册表。仅已注册队伍可获得训练数据。

- **结果提交**
  - 每队最多可提交三次任务。封闭模式为强制性，开放模式为可选。
  - 提交格式：数据集A、B和C分别对应训练集A、B和C。每个参赛团队必须提交三个格式化的JSON文件，格式与所提供训练数据格式相符。命名规则：TeamID_TestID_runID_modality.json，如14_TestA_1_open.json，表示编号为11的队伍第一次提交testA的开放模式结果。此外，在整理好所有JSON文件后，团队必须将它们打包成一个ZIP文件，最终提交时使用命名格式：TeamID_runID.zip。例如：11_3.zip表示编号为11的队伍进行第三次提交。
  - 截止时间：请在2026年2月9日23：50（UTC+8）之前通过 evahan2026@gmail.com 提交带注释的测试集结果。
  - 提交邮箱：每个队伍提交时，请使用报名邮箱提交，否组视为无效。
  - 每支队伍在截止日期前最多只能提交三次，最终得分将基于最新的提交。
  - 提交你的模型和代码以供验证。（可选）

- 技术报告：4–5页，LREC 2026官方模板，通过Softconf START系统提交（https://softconf.com/lrec2026/main）录用论文将正刊收录于LREC 2026会议论文集。

## 06 组织委员会

## 主办团队

南京农业大学信息管理学院

- 王东波、刘浏

南京师范大学语言大数据与计算人文研究中心

- 李斌、冯敏萱、许超、曲维光

南京理工大学经济管理学院

- 沈思

## 学生成员

南京农业大学信息管理学院

- 朱冬梅、厉洁琼、赵子墨、武瑞峰、杨俊羿、陆琪、杨桦婳、潘梦菲

南京师范大学文学院

- 许智星、李俊洁、朱月、徐梦婷

## 07 联系方式

- 邮箱：[evahan2026@gmail.com](mailto:evahan2026@gmail.com)
- GitHub：https://github.com/GoThereGit/EvaHan

## 08 协办单位

- 指导单位

-- 中国古籍保护协会古籍智能开发与利用专委会

- 协办单位（排名不分先后）

-- 中国人工智能学会语言智能专委会

-- 中文信息学会青年工作委员会

-- 中国民族语言学会语言资源与计算人文专委会

-- 江苏省人工智能学会自然语言处理专委会

-- 中华书局 古联（北京）数字传媒科技有限公司  

## 附录

OCR Models：

- DeepSeek-OCR: https://www.modelscope.cn/models/deepseek-ai/DeepSeek-OCR

- PaddleOCR-VL: https://www.modelscope.cn/models/PaddlePaddle/PaddleOCR-VL

- mscoder/duguang-ocr-onnx-v2: https://www.modelscope.cn/models/mscoder/duguang-ocr-onnx-v2

- RapidAI/RapidOCR: https://www.modelscope.cn/models/RapidAI/RapidOCR

- iic/cv_convnextTiny_ocr-recognition-document_damo: https://www.modelscope.cn/models/iic/cv_convnextTiny_ocr-recognition-document_damo

---

古籍智能，不止于文本，2026，我们一起让千年典籍“开口说话”！更多信息请持续关注“比特人文”公众号，我们将在12月1日正式开启注册通道！











