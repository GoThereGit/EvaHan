# 欢迎参赛 | EvaHan2026 古籍多模态OCR国际评测

<div align='center'>
<img src = 'https://user-images.githubusercontent.com/54113513/201254029-e63dd695-22aa-4419-ac01-7fc34326625a.png'>
</div>


[![En](https://img.shields.io/badge/README-English-blue.svg "English")](./README.md)

**English Version:** <a href="https://github.com/GoThereGit/EvaHan/blob/main/README_zh.md">CLICK ME</a> 

## 最新消息
评测报名入口：<a href="https://jsj.top/f/nWLK2R">点此跳转</a>

## 背景

中国古代典籍是中华文明最重要的载体之一，对其进行大规模数字化、智能化利用，是数字技术繁盛的当代，传承中华文明的重要方式。然而，光学字符识别（OCR）技术因古籍文本的异体字、残损笔迹等特殊难题，一直以来都是制约古籍文本实现大规模数字化、智能化的瓶颈。近年来，多模态大语言模型的迅猛发展，为突破上述技术瓶颈提供了新的可能。因此，如何科学评估其在复杂古籍图像（印刷体、版刻混排、手写体）上的OCR与版面分析能力，已成为当前领域的前沿课题。

为持续推动中文古籍智能处理技术发展，由南京农业大学、南京师范大学、南京理工大学等多单位联合主办的EvaHan 2026国际评测将于2026年正式开展，评测会议将于5月11日-5月16日在西班牙马略卡岛LREC 2026子会议上举办。这是第五届针对古代汉语语言技术的国际测评，本次测评聚焦于利用大语言模型（LLMs）进行古代汉语OCR识别任务，力图评价大语言模型的实际应用能力。

## 01 评测简介

光学字符识别（Optical Character Recognition，OCR）是一种将印刷或手写文本的图片转换为机器编码文本的基础技术。OCR的准确率与速率直接决定着系统整体性能，并影响文档数字化、信息提取及智能检索等下游应用的用户体验。然而，古籍文档的排版和布局与现代印刷存在显著差异，这使得海量基于现代文档数据开发的OCR技术及模型，在处理古籍相关图像时往往难以达到理想的识别效果。加之古籍本身存在文字形态复杂、版式多样等诸多特性，古籍OCR识别至今仍是一项颇具挑战的任务。

中国古代典籍承载着中华数千年的文化与历史信息，是传承民族文化基因的核心载体，其自动化处理有助于突破传统人工整理的效率瓶颈与资源限制，实现古籍文献的规模化、数字化存档，推动传统文化的活化利用与广泛传播，让珍贵典籍中的智慧成果更好服务于当代社会。迄今为止，EvaHan已成功举办了四届，有力推动了古籍智能分析技术的发展。

- 2022年（法国马赛）古汉语分词与词性标注国际评测
- 2023年（中国澳门）古汉语机器翻译国际评测
- 2024年（意大利都灵）古汉语自动句读与标点国际评测
- 2025年（美国阿尔伯克基）古汉语命名实体识别国际评测

EvaHan 2026国际评测组织者将会为参赛者提供统一的训练和测试数据集，参赛者则需要提交在测试集上的实验结果，由组织者评估参赛者最终提交的数据的真实性。

2026年，我们将目光转向更具挑战性的古籍多模态OCR任务，首次系统评估大语言模型在真实古籍图像上的端到端识别与版面理解能力。

## 02 评测方法

EvaHan 2026数据集包括三类图像文本对：纯文本图像、混合图文图像及手写文本图像，经过自动标注及专家修订后形成高质量的训练和测试集。数据来源包括：

- 数据集A（印刷文本）选自《四库全书》里的经史子集。 
- 数据集B（混合版式）包含从《四库全书》及其他古籍中选取的混合图文数据。 
- 数据集C（手写文本）涵盖手写古籍，主要为汉文佛典，包含《汉文佛典（TKH）》数据集与《汉文佛典（MTH）》数据集。

数据集被分成训练集（约15,000–30,000组）与测试集（每个子集约200–500组），所有评估数据均采用“图像-文本”对形式，文本以Unicode（UTF-8）编码的txt文件存储。

 

核心评估维度：

- OCR性能：CER(字错率)、准确率（Precision）、召回率（Recall）、F1-Score和NED（归一化编辑距离）
- 版面分析指标：mAP、微平均F1、宏平均F1、IoU

测试数据的详细信息和下载链接，均将在正式评估期开始前提供给参与者。

## 03 两种参赛模式

- 封闭模式（强制）：仅允许使用官方训练数据 + 允许的预训练视觉 - 语言模型（基准线基于Qwen2.5_VL_7B_Instruct     https://www.modelscope.cn/models/Qwen/Qwen2.5-VL-7B-Instruct）
- 开放模式（可选）：不限制外部资源、数据、模型，但需在技术报告中完整披露所有选用资源。

每队最多可提交3次运行（两种模式相加总次数为3），最终评分以最后一次提交的运行为准。

## 04 重要时间节点

- 注册开放：2025年12月1日
- 训练数据发布：2026年1月1日
- 注册截止：2026年1月30日
- 测试数据发布：2026年2月1日
- 结果提交截止：2026年2月6日 23:59（UTC+8）
- 技术报告提交截止：2026年2月28日
- 录用通知：2026年3月1日
- 论文终稿提交：2026年3月10日
- 会议时间：2026年5月11日 - 16日（西班牙·马略卡岛）

## 05 参赛方式

- 注册：2025年12月1日–2026年1月30日，发送邮件至[evahan2026@gmail.com](mailto:evahan2026@gmail.com)索取并提交注册表。仅已注册队伍可获得训练数据。
- 结果提交：将三个子任务的纯文本识别结果（UTF - 8）打包发送至官方邮箱，同时附上可复现代码。
- 技术报告：4–8页，LREC 2026官方模板，通过Softconf START系统提交（https://softconf.com/lrec2026/main）录用论文将正刊收录于LREC 2026会议论文集。

## 06 组织委员会（按文档顺序）

## 主办团队

南京农业大学信息管理学院

- 王东波、刘浏

南京师范大学语言大数据与计算人文研究中心

- 李斌、冯敏萱、许超、曲维光

南京理工大学经济管理学院

- 沈思

## 学生成员

南京农业大学信息管理学院

- 朱冬梅、厉洁琼、赵子墨、武瑞峰、杨俊羿、陆琪、杨桦婳、潘梦菲

南京师范大学文学院

- 许智星、李俊洁、朱月、徐梦婷

## 07 联系方式

- 邮箱：[evahan2026@gmail.com](mailto:evahan2026@gmail.com)
- GitHub：https://github.com/GoThereGit/EvaHan

## 08 协办单位

- 指导单位

-- 中国古籍保护协会古籍智能开发与利用专委会
- 协办单位（排名不分先后）

-- 中国人工智能学会语言智能专委会

-- 中文信息学会青年工作委员会

-- 中国民族语言学会语言资源与计算人文专委会

-- 江苏省人工智能学会自然语言处理专委会

-- 中华书局 古联（北京）数字传媒科技有限公司  

## 附录

OCR Models：

- DeepSeek-OCR: https://www.modelscope.cn/models/deepseek-ai/DeepSeek-OCR

- PaddleOCR-VL: https://www.modelscope.cn/models/PaddlePaddle/PaddleOCR-VL

- mscoder/duguang-ocr-onnx-v2: https://www.modelscope.cn/models/mscoder/duguang-ocr-onnx-v2

- RapidAI/RapidOCR: https://www.modelscope.cn/models/RapidAI/RapidOCR

- iic/cv_convnextTiny_ocr-recognition-document_damo: https://www.modelscope.cn/models/iic/cv_convnextTiny_ocr-recognition-document_damo

---

古籍智能，不止于文本，2026，我们一起让千年典籍“开口说话”！更多信息请持续关注“比特人文”公众号，我们将在12月1日正式开启注册通道！





